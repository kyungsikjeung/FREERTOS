<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.14.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RTOS: Softmax Functions</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">RTOS<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.14.0 -->
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<div id="main-nav">
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li class="current"><a href="topics.html"><span>Topics</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
    </ul>
  </div>
</div><!-- main-nav -->
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">Softmax Functions <div class="ingroups"><a class="el" href="group__group_support.html">Support Functions</a> &#124; <a class="el" href="group__group_n_n.html">Neural Network Functions</a></div></div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Collaboration diagram for Softmax Functions:</div>
<div class="dyncontent">
<div class="center"><img src="group___softmax.png" border="0" usemap="#agroup______softmax" loading="lazy" alt=""/></div>
<map name="agroup______softmax" id="agroup______softmax">
<area shape="rect" title=" " alt="" coords="227,31,358,57"/>
<area shape="rect" href="group__group_n_n.html" title=" " alt="" coords="5,5,179,32"/>
<area shape="rect" href="group__group_support.html" title=" " alt="" coords="28,56,156,83"/>
</map>
</div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-func-members" class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:gaa5632ba67b623b5dff0c4a2d8e2a9a3a" id="r_gaa5632ba67b623b5dff0c4a2d8e2a9a3a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaa5632ba67b623b5dff0c4a2d8e2a9a3a">arm_nn_softmax_common_s8</a> (const int8_t *input, const int32_t num_rows, const int32_t row_size, const int32_t mult, const int32_t shift, const int32_t diff_min, const bool int16_output, void *output)</td></tr>
<tr class="memdesc:gaa5632ba67b623b5dff0c4a2d8e2a9a3a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Common softmax function for s8 input and s8 or s16 output.  <br /></td></tr>
<tr class="memitem:ga1cacd8b84b8363079311987d0016ebe5" id="r_ga1cacd8b84b8363079311987d0016ebe5"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga1cacd8b84b8363079311987d0016ebe5">arm_softmax_q15</a> (const <a class="el" href="arm__math__types_8h.html#ab5a8fb21a5b3b983d5f54f31614052ea">q15_t</a> *vec_in, const uint16_t dim_vec, <a class="el" href="arm__math__types_8h.html#ab5a8fb21a5b3b983d5f54f31614052ea">q15_t</a> *p_out)</td></tr>
<tr class="memdesc:ga1cacd8b84b8363079311987d0016ebe5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Q15 softmax function.  <br /></td></tr>
<tr class="memitem:ga89aff212a97a3cf32d9d7ddf11a8f43e" id="r_ga89aff212a97a3cf32d9d7ddf11a8f43e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga89aff212a97a3cf32d9d7ddf11a8f43e">arm_softmax_q7</a> (const <a class="el" href="arm__math__types_8h.html#ae541b6f232c305361e9b416fc9eed263">q7_t</a> *vec_in, const uint16_t dim_vec, <a class="el" href="arm__math__types_8h.html#ae541b6f232c305361e9b416fc9eed263">q7_t</a> *p_out)</td></tr>
<tr class="memdesc:ga89aff212a97a3cf32d9d7ddf11a8f43e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Q7 softmax function.  <br /></td></tr>
<tr class="memitem:ga3bc3ad13727a8a9d2cf7d0fba1209879" id="r_ga3bc3ad13727a8a9d2cf7d0fba1209879"><td class="memItemLeft" align="right" valign="top"><a class="el" href="arm__math__types_8h.html#a5e459c6409dfcd2927bb8a57491d7cf6">arm_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga3bc3ad13727a8a9d2cf7d0fba1209879">arm_softmax_s16</a> (const int16_t *input, const int32_t num_rows, const int32_t row_size, const int32_t mult, const int32_t shift, const <a class="el" href="structcmsis__nn__softmax__lut__s16.html">cmsis_nn_softmax_lut_s16</a> *softmax_params, int16_t *output)</td></tr>
<tr class="memdesc:ga3bc3ad13727a8a9d2cf7d0fba1209879"><td class="mdescLeft">&#160;</td><td class="mdescRight">S16 softmax function.  <br /></td></tr>
<tr class="memitem:gaf309cdd53978a85a39c9bfdc476aea17" id="r_gaf309cdd53978a85a39c9bfdc476aea17"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaf309cdd53978a85a39c9bfdc476aea17">arm_softmax_s8</a> (const int8_t *input, const int32_t num_rows, const int32_t row_size, const int32_t mult, const int32_t shift, const int32_t diff_min, int8_t *output)</td></tr>
<tr class="memdesc:gaf309cdd53978a85a39c9bfdc476aea17"><td class="mdescLeft">&#160;</td><td class="mdescRight">S8 softmax function.  <br /></td></tr>
<tr class="memitem:ga4c00979132b735e75525296bb5fa830f" id="r_ga4c00979132b735e75525296bb5fa830f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga4c00979132b735e75525296bb5fa830f">arm_softmax_s8_s16</a> (const int8_t *input, const int32_t num_rows, const int32_t row_size, const int32_t mult, const int32_t shift, const int32_t diff_min, int16_t *output)</td></tr>
<tr class="memdesc:ga4c00979132b735e75525296bb5fa830f"><td class="mdescLeft">&#160;</td><td class="mdescRight">S8 to s16 softmax function.  <br /></td></tr>
<tr class="memitem:gaa1627ed96bd597a8046d00689f077dce" id="r_gaa1627ed96bd597a8046d00689f077dce"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaa1627ed96bd597a8046d00689f077dce">arm_softmax_u8</a> (const uint8_t *input, const int32_t num_rows, const int32_t row_size, const int32_t mult, const int32_t shift, const int32_t diff_min, uint8_t *output)</td></tr>
<tr class="memdesc:gaa1627ed96bd597a8046d00689f077dce"><td class="mdescLeft">&#160;</td><td class="mdescRight">U8 softmax function.  <br /></td></tr>
<tr class="memitem:ga894cfd80c260b946702755b5754e520f" id="r_ga894cfd80c260b946702755b5754e520f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga894cfd80c260b946702755b5754e520f">arm_softmax_with_batch_q7</a> (const <a class="el" href="arm__math__types_8h.html#ae541b6f232c305361e9b416fc9eed263">q7_t</a> *vec_in, const uint16_t nb_batches, const uint16_t dim_vec, <a class="el" href="arm__math__types_8h.html#ae541b6f232c305361e9b416fc9eed263">q7_t</a> *p_out)</td></tr>
<tr class="memdesc:ga894cfd80c260b946702755b5754e520f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Q7 softmax function with batch parameter.  <br /></td></tr>
</table>
<a name="details" id="details"></a><h2 id="header-details" class="groupheader">Detailed Description</h2>
<p>EXP(2) based softmax functions.</p>
<a name="doc-func-members" id="doc-func-members"></a><h2 id="header-doc-func-members" class="groupheader">Function Documentation</h2>
<a id="gaa5632ba67b623b5dff0c4a2d8e2a9a3a" name="gaa5632ba67b623b5dff0c4a2d8e2a9a3a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa5632ba67b623b5dff0c4a2d8e2a9a3a">&#9670;&#160;</a></span>arm_nn_softmax_common_s8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void arm_nn_softmax_common_s8 </td>
          <td>(</td>
          <td class="paramtype">const int8_t *</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>num_rows</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>row_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>mult</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>diff_min</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const bool</td>          <td class="paramname"><span class="paramname"><em>int16_output</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *</td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Common softmax function for s8 input and s8 or s16 output. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Pointer to the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_rows</td><td>Number of rows in the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">row_size</td><td>Number of elements in each input row </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">mult</td><td>Input quantization multiplier </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">shift</td><td>Input quantization shift within the range [0, 31] </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">diff_min</td><td>Minimum difference with max in row. Used to check if the quantized exponential operation can be performed </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">int16_output</td><td>Indicating s8 output if 0 else s16 output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Pointer to the output tensor</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>Supported framework: TensorFlow Lite micro (bit-accurate) </dd></dl>

<p class="definition">Definition at line <a class="el" href="arm__nn__softmax__common__s8_8c_source.html#l00049">49</a> of file <a class="el" href="arm__nn__softmax__common__s8_8c_source.html">arm_nn_softmax_common_s8.c</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="group___softmax_gaa5632ba67b623b5dff0c4a2d8e2a9a3a_icgraph.png" border="0" usemap="#agroup___softmax_gaa5632ba67b623b5dff0c4a2d8e2a9a3a_icgraph" loading="lazy" alt=""/></div>
<map name="agroup___softmax_gaa5632ba67b623b5dff0c4a2d8e2a9a3a_icgraph" id="agroup___softmax_gaa5632ba67b623b5dff0c4a2d8e2a9a3a_icgraph">
<area shape="rect" title="Common softmax function for s8 input and s8 or s16 output." alt="" coords="200,31,396,57"/>
<area shape="rect" href="group___softmax.html#gaf309cdd53978a85a39c9bfdc476aea17" title="S8 softmax function." alt="" coords="19,5,138,32"/>
<area shape="poly" title=" " alt="" coords="184,34,138,28,138,23,185,28"/>
<area shape="rect" href="group___softmax.html#ga4c00979132b735e75525296bb5fa830f" title="S8 to s16 softmax function." alt="" coords="5,56,152,83"/>
<area shape="poly" title=" " alt="" coords="185,60,152,64,152,58,184,54"/>
</map>
</div>

</div>
</div>
<a id="ga1cacd8b84b8363079311987d0016ebe5" name="ga1cacd8b84b8363079311987d0016ebe5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1cacd8b84b8363079311987d0016ebe5">&#9670;&#160;</a></span>arm_softmax_q15()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void arm_softmax_q15 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="arm__math__types_8h.html#ab5a8fb21a5b3b983d5f54f31614052ea">q15_t</a> *</td>          <td class="paramname"><span class="paramname"><em>vec_in</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>dim_vec</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="arm__math__types_8h.html#ab5a8fb21a5b3b983d5f54f31614052ea">q15_t</a> *</td>          <td class="paramname"><span class="paramname"><em>p_out</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Q15 softmax function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">vec_in</td><td>pointer to input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dim_vec</td><td>input vector dimention </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">p_out</td><td>pointer to output vector</td></tr>
  </table>
  </dd>
</dl>
<p>Here, instead of typical e based softmax, we use 2-based softmax, i.e.,:</p>
<p>y_i = 2^(x_i) / sum(2^x_j)</p>
<p>The relative output will be different here. But mathematically, the gradient will be the same with a log(2) scaling factor. </p>

<p class="definition">Definition at line <a class="el" href="arm__softmax__q15_8c_source.html#l00061">61</a> of file <a class="el" href="arm__softmax__q15_8c_source.html">arm_softmax_q15.c</a>.</p>

</div>
</div>
<a id="ga89aff212a97a3cf32d9d7ddf11a8f43e" name="ga89aff212a97a3cf32d9d7ddf11a8f43e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga89aff212a97a3cf32d9d7ddf11a8f43e">&#9670;&#160;</a></span>arm_softmax_q7()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void arm_softmax_q7 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="arm__math__types_8h.html#ae541b6f232c305361e9b416fc9eed263">q7_t</a> *</td>          <td class="paramname"><span class="paramname"><em>vec_in</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>dim_vec</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="arm__math__types_8h.html#ae541b6f232c305361e9b416fc9eed263">q7_t</a> *</td>          <td class="paramname"><span class="paramname"><em>p_out</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Q7 softmax function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">vec_in</td><td>pointer to input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dim_vec</td><td>input vector dimention </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">p_out</td><td>pointer to output vector</td></tr>
  </table>
  </dd>
</dl>
<p>Here, instead of typical natural logarithm e based softmax, we use 2-based softmax here, i.e.,:</p>
<p>y_i = 2^(x_i) / sum(2^x_j)</p>
<p>The relative output will be different here. But mathematically, the gradient will be the same with a log(2) scaling factor. </p>

<p class="definition">Definition at line <a class="el" href="arm__softmax__q7_8c_source.html#l00061">61</a> of file <a class="el" href="arm__softmax__q7_8c_source.html">arm_softmax_q7.c</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="group___softmax_ga89aff212a97a3cf32d9d7ddf11a8f43e_icgraph.png" border="0" usemap="#agroup___softmax_ga89aff212a97a3cf32d9d7ddf11a8f43e_icgraph" loading="lazy" alt=""/></div>
<map name="agroup___softmax_ga89aff212a97a3cf32d9d7ddf11a8f43e_icgraph" id="agroup___softmax_ga89aff212a97a3cf32d9d7ddf11a8f43e_icgraph">
<area shape="rect" title="Q7 softmax function." alt="" coords="242,5,360,32"/>
<area shape="rect" href="group___softmax.html#ga894cfd80c260b946702755b5754e520f" title="Q7 softmax function with batch parameter." alt="" coords="5,5,194,32"/>
<area shape="poly" title=" " alt="" coords="226,21,194,21,194,16,226,16"/>
</map>
</div>

</div>
</div>
<a id="ga3bc3ad13727a8a9d2cf7d0fba1209879" name="ga3bc3ad13727a8a9d2cf7d0fba1209879"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3bc3ad13727a8a9d2cf7d0fba1209879">&#9670;&#160;</a></span>arm_softmax_s16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="arm__math__types_8h.html#a5e459c6409dfcd2927bb8a57491d7cf6">arm_status</a> arm_softmax_s16 </td>
          <td>(</td>
          <td class="paramtype">const int16_t *</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>num_rows</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>row_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>mult</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structcmsis__nn__softmax__lut__s16.html">cmsis_nn_softmax_lut_s16</a> *</td>          <td class="paramname"><span class="paramname"><em>softmax_params</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int16_t *</td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>S16 softmax function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Pointer to the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_rows</td><td>Number of rows in the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">row_size</td><td>Number of elements in each input row </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">mult</td><td>Input quantization multiplier </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">shift</td><td>Input quantization shift within the range [0, 31] </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">softmax_params</td><td>Softmax s16 layer parameters with two pointers to LUTs speficied below. For indexing the high 9 bits are used and 7 remaining for interpolation. That means 512 entries for the 9-bit indexing and 1 extra for interpolation, i.e. 513 values for each LUT.<ul>
<li>Lookup table for exp(x), where x uniform distributed between [-10.0 , 0.0]</li>
<li>Lookup table for 1 / (1 + x), where x uniform distributed between [0.0 , 1.0] </li>
</ul>
</td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Pointer to the output tensor </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>ARM_MATH_ARGUMENT_ERROR</code> if LUTs are NULL <code>ARM_MATH_SUCCESS</code> - Successful operation</dd></dl>
<dl class="section note"><dt>Note</dt><dd>Supported framework: TensorFlow Lite micro (bit-accurate) </dd></dl>

<p class="definition">Definition at line <a class="el" href="arm__softmax__s16_8c_source.html#l00039">39</a> of file <a class="el" href="arm__softmax__s16_8c_source.html">arm_softmax_s16.c</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="group___softmax_ga3bc3ad13727a8a9d2cf7d0fba1209879_cgraph.png" border="0" usemap="#agroup___softmax_ga3bc3ad13727a8a9d2cf7d0fba1209879_cgraph" loading="lazy" alt=""/></div>
<map name="agroup___softmax_ga3bc3ad13727a8a9d2cf7d0fba1209879_cgraph" id="agroup___softmax_ga3bc3ad13727a8a9d2cf7d0fba1209879_cgraph">
<area shape="rect" title="S16 softmax function." alt="" coords="5,47,131,73"/>
<area shape="rect" href="arm__nnsupportfunctions_8h.html#a6a13b7a567485da5fc7f0d311318886d" title="Requantize a given value." alt="" coords="179,47,310,73"/>
<area shape="poly" title=" " alt="" coords="131,57,163,57,163,63,131,63"/>
<area shape="rect" href="arm__nnsupportfunctions_8h.html#ab6dbc2fd53fae3ccdd1d0d70c8d3b491" title="Rounding divide by power of two." alt="" coords="358,5,526,48"/>
<area shape="poly" title=" " alt="" coords="310,46,342,41,343,46,311,52"/>
<area shape="rect" href="arm__nnsupportfunctions_8h.html#a4e5183e2400227aafc91fb796fe99a6d" title="Doubling high multiply without saturation. This is intended for requantization where the scale is a p..." alt="" coords="367,72,517,115"/>
<area shape="poly" title=" " alt="" coords="311,68,352,75,351,81,310,74"/>
</map>
</div>

</div>
</div>
<a id="gaf309cdd53978a85a39c9bfdc476aea17" name="gaf309cdd53978a85a39c9bfdc476aea17"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf309cdd53978a85a39c9bfdc476aea17">&#9670;&#160;</a></span>arm_softmax_s8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void arm_softmax_s8 </td>
          <td>(</td>
          <td class="paramtype">const int8_t *</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>num_rows</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>row_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>mult</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>diff_min</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *</td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>S8 softmax function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Pointer to the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_rows</td><td>Number of rows in the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">row_size</td><td>Number of elements in each input row </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">mult</td><td>Input quantization multiplier </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">shift</td><td>Input quantization shift within the range [0, 31] </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">diff_min</td><td>Minimum difference with max in row. Used to check if the quantized exponential operation can be performed </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Pointer to the output tensor</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>Supported framework: TensorFlow Lite micro (bit-accurate) </dd></dl>

<p class="definition">Definition at line <a class="el" href="arm__softmax__s8_8c_source.html#l00086">86</a> of file <a class="el" href="arm__softmax__s8_8c_source.html">arm_softmax_s8.c</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="group___softmax_gaf309cdd53978a85a39c9bfdc476aea17_cgraph.png" border="0" usemap="#agroup___softmax_gaf309cdd53978a85a39c9bfdc476aea17_cgraph" loading="lazy" alt=""/></div>
<map name="agroup___softmax_gaf309cdd53978a85a39c9bfdc476aea17_cgraph" id="agroup___softmax_gaf309cdd53978a85a39c9bfdc476aea17_cgraph">
<area shape="rect" title="S8 softmax function." alt="" coords="5,5,124,32"/>
<area shape="rect" href="group___softmax.html#gaa5632ba67b623b5dff0c4a2d8e2a9a3a" title="Common softmax function for s8 input and s8 or s16 output." alt="" coords="172,5,368,32"/>
<area shape="poly" title=" " alt="" coords="124,16,156,16,156,21,124,21"/>
</map>
</div>

</div>
</div>
<a id="ga4c00979132b735e75525296bb5fa830f" name="ga4c00979132b735e75525296bb5fa830f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4c00979132b735e75525296bb5fa830f">&#9670;&#160;</a></span>arm_softmax_s8_s16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void arm_softmax_s8_s16 </td>
          <td>(</td>
          <td class="paramtype">const int8_t *</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>num_rows</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>row_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>mult</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>diff_min</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int16_t *</td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>S8 to s16 softmax function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Pointer to the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_rows</td><td>Number of rows in the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">row_size</td><td>Number of elements in each input row </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">mult</td><td>Input quantization multiplier </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">shift</td><td>Input quantization shift within the range [0, 31] </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">diff_min</td><td>Minimum difference with max in row. Used to check if the quantized exponential operation can be performed </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Pointer to the output tensor</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>Supported framework: TensorFlow Lite micro (bit-accurate) </dd></dl>

<p class="definition">Definition at line <a class="el" href="arm__softmax__s8__s16_8c_source.html#l00043">43</a> of file <a class="el" href="arm__softmax__s8__s16_8c_source.html">arm_softmax_s8_s16.c</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="group___softmax_ga4c00979132b735e75525296bb5fa830f_cgraph.png" border="0" usemap="#agroup___softmax_ga4c00979132b735e75525296bb5fa830f_cgraph" loading="lazy" alt=""/></div>
<map name="agroup___softmax_ga4c00979132b735e75525296bb5fa830f_cgraph" id="agroup___softmax_ga4c00979132b735e75525296bb5fa830f_cgraph">
<area shape="rect" title="S8 to s16 softmax function." alt="" coords="5,5,152,32"/>
<area shape="rect" href="group___softmax.html#gaa5632ba67b623b5dff0c4a2d8e2a9a3a" title="Common softmax function for s8 input and s8 or s16 output." alt="" coords="200,5,396,32"/>
<area shape="poly" title=" " alt="" coords="152,16,184,16,184,21,152,21"/>
</map>
</div>

</div>
</div>
<a id="gaa1627ed96bd597a8046d00689f077dce" name="gaa1627ed96bd597a8046d00689f077dce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa1627ed96bd597a8046d00689f077dce">&#9670;&#160;</a></span>arm_softmax_u8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void arm_softmax_u8 </td>
          <td>(</td>
          <td class="paramtype">const uint8_t *</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>num_rows</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>row_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>mult</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>diff_min</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint8_t *</td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>U8 softmax function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Pointer to the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_rows</td><td>Number of rows in the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">row_size</td><td>Number of elements in each input row </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">mult</td><td>Input quantization multiplier </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">shift</td><td>Input quantization shift within the range [0, 31] </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">diff_min</td><td>Minimum difference with max in row. Used to check if the quantized exponential operation can be performed </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Pointer to the output tensor</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>Supported framework: TensorFlow Lite micro (bit-accurate) </dd></dl>

<p class="definition">Definition at line <a class="el" href="arm__softmax__u8_8c_source.html#l00044">44</a> of file <a class="el" href="arm__softmax__u8_8c_source.html">arm_softmax_u8.c</a>.</p>

</div>
</div>
<a id="ga894cfd80c260b946702755b5754e520f" name="ga894cfd80c260b946702755b5754e520f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga894cfd80c260b946702755b5754e520f">&#9670;&#160;</a></span>arm_softmax_with_batch_q7()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void arm_softmax_with_batch_q7 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="arm__math__types_8h.html#ae541b6f232c305361e9b416fc9eed263">q7_t</a> *</td>          <td class="paramname"><span class="paramname"><em>vec_in</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>nb_batches</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>dim_vec</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="arm__math__types_8h.html#ae541b6f232c305361e9b416fc9eed263">q7_t</a> *</td>          <td class="paramname"><span class="paramname"><em>p_out</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Q7 softmax function with batch parameter. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">vec_in</td><td>pointer to input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">nb_batches</td><td>number of batches </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dim_vec</td><td>input vector dimention </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">p_out</td><td>pointer to output vector</td></tr>
  </table>
  </dd>
</dl>
<p>Here, instead of typical natural logarithm e based softmax, we use 2-based softmax here, i.e.,:</p>
<p>y_i = 2^(x_i) / sum(2^x_j)</p>
<p>The relative output will be different here. But mathematically, the gradient will be the same with a log(2) scaling factor. </p>

<p class="definition">Definition at line <a class="el" href="arm__softmax__with__batch__q7_8c_source.html#l00062">62</a> of file <a class="el" href="arm__softmax__with__batch__q7_8c_source.html">arm_softmax_with_batch_q7.c</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="group___softmax_ga894cfd80c260b946702755b5754e520f_cgraph.png" border="0" usemap="#agroup___softmax_ga894cfd80c260b946702755b5754e520f_cgraph" loading="lazy" alt=""/></div>
<map name="agroup___softmax_ga894cfd80c260b946702755b5754e520f_cgraph" id="agroup___softmax_ga894cfd80c260b946702755b5754e520f_cgraph">
<area shape="rect" title="Q7 softmax function with batch parameter." alt="" coords="5,5,194,32"/>
<area shape="rect" href="group___softmax.html#ga89aff212a97a3cf32d9d7ddf11a8f43e" title="Q7 softmax function." alt="" coords="242,5,360,32"/>
<area shape="poly" title=" " alt="" coords="194,16,226,16,226,21,194,21"/>
</map>
</div>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.14.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
