\doxysubsection{Softmax Functions }
\hypertarget{group___softmax}{}\label{group___softmax}\index{Softmax Functions@{Softmax Functions}}
Collaboration diagram for Softmax Functions\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=345pt]{group___softmax}
\end{center}
\end{figure}
\doxysubsubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
void \mbox{\hyperlink{group___softmax_gaa5632ba67b623b5dff0c4a2d8e2a9a3a}{arm\+\_\+nn\+\_\+softmax\+\_\+common\+\_\+s8}} (const int8\+\_\+t \texorpdfstring{$\ast$}{*}input, const int32\+\_\+t num\+\_\+rows, const int32\+\_\+t row\+\_\+size, const int32\+\_\+t mult, const int32\+\_\+t shift, const int32\+\_\+t diff\+\_\+min, const bool int16\+\_\+output, void \texorpdfstring{$\ast$}{*}output)
\begin{DoxyCompactList}\small\item\em Common softmax function for s8 input and s8 or s16 output. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{group___softmax_ga1cacd8b84b8363079311987d0016ebe5}{arm\+\_\+softmax\+\_\+q15}} (const \mbox{\hyperlink{arm__math__types_8h_ab5a8fb21a5b3b983d5f54f31614052ea}{q15\+\_\+t}} \texorpdfstring{$\ast$}{*}vec\+\_\+in, const uint16\+\_\+t dim\+\_\+vec, \mbox{\hyperlink{arm__math__types_8h_ab5a8fb21a5b3b983d5f54f31614052ea}{q15\+\_\+t}} \texorpdfstring{$\ast$}{*}p\+\_\+out)
\begin{DoxyCompactList}\small\item\em Q15 softmax function. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{group___softmax_ga89aff212a97a3cf32d9d7ddf11a8f43e}{arm\+\_\+softmax\+\_\+q7}} (const \mbox{\hyperlink{arm__math__types_8h_ae541b6f232c305361e9b416fc9eed263}{q7\+\_\+t}} \texorpdfstring{$\ast$}{*}vec\+\_\+in, const uint16\+\_\+t dim\+\_\+vec, \mbox{\hyperlink{arm__math__types_8h_ae541b6f232c305361e9b416fc9eed263}{q7\+\_\+t}} \texorpdfstring{$\ast$}{*}p\+\_\+out)
\begin{DoxyCompactList}\small\item\em Q7 softmax function. \end{DoxyCompactList}\item 
\mbox{\hyperlink{arm__math__types_8h_a5e459c6409dfcd2927bb8a57491d7cf6}{arm\+\_\+status}} \mbox{\hyperlink{group___softmax_ga3bc3ad13727a8a9d2cf7d0fba1209879}{arm\+\_\+softmax\+\_\+s16}} (const int16\+\_\+t \texorpdfstring{$\ast$}{*}input, const int32\+\_\+t num\+\_\+rows, const int32\+\_\+t row\+\_\+size, const int32\+\_\+t mult, const int32\+\_\+t shift, const \mbox{\hyperlink{structcmsis__nn__softmax__lut__s16}{cmsis\+\_\+nn\+\_\+softmax\+\_\+lut\+\_\+s16}} \texorpdfstring{$\ast$}{*}softmax\+\_\+params, int16\+\_\+t \texorpdfstring{$\ast$}{*}output)
\begin{DoxyCompactList}\small\item\em S16 softmax function. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{group___softmax_gaf309cdd53978a85a39c9bfdc476aea17}{arm\+\_\+softmax\+\_\+s8}} (const int8\+\_\+t \texorpdfstring{$\ast$}{*}input, const int32\+\_\+t num\+\_\+rows, const int32\+\_\+t row\+\_\+size, const int32\+\_\+t mult, const int32\+\_\+t shift, const int32\+\_\+t diff\+\_\+min, int8\+\_\+t \texorpdfstring{$\ast$}{*}output)
\begin{DoxyCompactList}\small\item\em S8 softmax function. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{group___softmax_ga4c00979132b735e75525296bb5fa830f}{arm\+\_\+softmax\+\_\+s8\+\_\+s16}} (const int8\+\_\+t \texorpdfstring{$\ast$}{*}input, const int32\+\_\+t num\+\_\+rows, const int32\+\_\+t row\+\_\+size, const int32\+\_\+t mult, const int32\+\_\+t shift, const int32\+\_\+t diff\+\_\+min, int16\+\_\+t \texorpdfstring{$\ast$}{*}output)
\begin{DoxyCompactList}\small\item\em S8 to s16 softmax function. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{group___softmax_gaa1627ed96bd597a8046d00689f077dce}{arm\+\_\+softmax\+\_\+u8}} (const uint8\+\_\+t \texorpdfstring{$\ast$}{*}input, const int32\+\_\+t num\+\_\+rows, const int32\+\_\+t row\+\_\+size, const int32\+\_\+t mult, const int32\+\_\+t shift, const int32\+\_\+t diff\+\_\+min, uint8\+\_\+t \texorpdfstring{$\ast$}{*}output)
\begin{DoxyCompactList}\small\item\em U8 softmax function. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{group___softmax_ga894cfd80c260b946702755b5754e520f}{arm\+\_\+softmax\+\_\+with\+\_\+batch\+\_\+q7}} (const \mbox{\hyperlink{arm__math__types_8h_ae541b6f232c305361e9b416fc9eed263}{q7\+\_\+t}} \texorpdfstring{$\ast$}{*}vec\+\_\+in, const uint16\+\_\+t nb\+\_\+batches, const uint16\+\_\+t dim\+\_\+vec, \mbox{\hyperlink{arm__math__types_8h_ae541b6f232c305361e9b416fc9eed263}{q7\+\_\+t}} \texorpdfstring{$\ast$}{*}p\+\_\+out)
\begin{DoxyCompactList}\small\item\em Q7 softmax function with batch parameter. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsubsection{Detailed Description}
EXP(2) based softmax functions.

\label{doc-func-members}
\Hypertarget{group___softmax_doc-func-members}
\doxysubsubsection{Function Documentation}
\Hypertarget{group___softmax_gaa5632ba67b623b5dff0c4a2d8e2a9a3a}\index{Softmax Functions@{Softmax Functions}!arm\_nn\_softmax\_common\_s8@{arm\_nn\_softmax\_common\_s8}}
\index{arm\_nn\_softmax\_common\_s8@{arm\_nn\_softmax\_common\_s8}!Softmax Functions@{Softmax Functions}}
\doxysubsubsubsection{\texorpdfstring{arm\_nn\_softmax\_common\_s8()}{arm\_nn\_softmax\_common\_s8()}}
{\footnotesize\ttfamily \label{group___softmax_gaa5632ba67b623b5dff0c4a2d8e2a9a3a} 
void arm\+\_\+nn\+\_\+softmax\+\_\+common\+\_\+s8 (\begin{DoxyParamCaption}\item[{const int8\+\_\+t \texorpdfstring{$\ast$}{*}}]{input}{, }\item[{const int32\+\_\+t}]{num\+\_\+rows}{, }\item[{const int32\+\_\+t}]{row\+\_\+size}{, }\item[{const int32\+\_\+t}]{mult}{, }\item[{const int32\+\_\+t}]{shift}{, }\item[{const int32\+\_\+t}]{diff\+\_\+min}{, }\item[{const bool}]{int16\+\_\+output}{, }\item[{void \texorpdfstring{$\ast$}{*}}]{output}{}\end{DoxyParamCaption})}



Common softmax function for s8 input and s8 or s16 output. 


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{in}}  & {\em input} & Pointer to the input tensor \\
\hline
\mbox{\texttt{in}}  & {\em num\+\_\+rows} & Number of rows in the input tensor \\
\hline
\mbox{\texttt{in}}  & {\em row\+\_\+size} & Number of elements in each input row \\
\hline
\mbox{\texttt{in}}  & {\em mult} & Input quantization multiplier \\
\hline
\mbox{\texttt{in}}  & {\em shift} & Input quantization shift within the range \mbox{[}0, 31\mbox{]} \\
\hline
\mbox{\texttt{in}}  & {\em diff\+\_\+min} & Minimum difference with max in row. Used to check if the quantized exponential operation can be performed \\
\hline
\mbox{\texttt{in}}  & {\em int16\+\_\+output} & Indicating s8 output if 0 else s16 output \\
\hline
\mbox{\texttt{out}}  & {\em output} & Pointer to the output tensor\\
\hline
\end{DoxyParams}
\begin{DoxyNote}{Note}
Supported framework\+: Tensor\+Flow Lite micro (bit-\/accurate) 
\end{DoxyNote}


Definition at line \mbox{\hyperlink{arm__nn__softmax__common__s8_8c_source_l00049}{49}} of file \mbox{\hyperlink{arm__nn__softmax__common__s8_8c_source}{arm\+\_\+nn\+\_\+softmax\+\_\+common\+\_\+s8.\+c}}.

Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{group___softmax_gaa5632ba67b623b5dff0c4a2d8e2a9a3a_icgraph}
\end{center}
\end{figure}
\Hypertarget{group___softmax_ga1cacd8b84b8363079311987d0016ebe5}\index{Softmax Functions@{Softmax Functions}!arm\_softmax\_q15@{arm\_softmax\_q15}}
\index{arm\_softmax\_q15@{arm\_softmax\_q15}!Softmax Functions@{Softmax Functions}}
\doxysubsubsubsection{\texorpdfstring{arm\_softmax\_q15()}{arm\_softmax\_q15()}}
{\footnotesize\ttfamily \label{group___softmax_ga1cacd8b84b8363079311987d0016ebe5} 
void arm\+\_\+softmax\+\_\+q15 (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{arm__math__types_8h_ab5a8fb21a5b3b983d5f54f31614052ea}{q15\+\_\+t}} \texorpdfstring{$\ast$}{*}}]{vec\+\_\+in}{, }\item[{const uint16\+\_\+t}]{dim\+\_\+vec}{, }\item[{\mbox{\hyperlink{arm__math__types_8h_ab5a8fb21a5b3b983d5f54f31614052ea}{q15\+\_\+t}} \texorpdfstring{$\ast$}{*}}]{p\+\_\+out}{}\end{DoxyParamCaption})}



Q15 softmax function. 


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{in}}  & {\em vec\+\_\+in} & pointer to input vector \\
\hline
\mbox{\texttt{in}}  & {\em dim\+\_\+vec} & input vector dimention \\
\hline
\mbox{\texttt{out}}  & {\em p\+\_\+out} & pointer to output vector\\
\hline
\end{DoxyParams}
Here, instead of typical e based softmax, we use 2-\/based softmax, i.\+e.,\+:

y\+\_\+i = 2\texorpdfstring{$^\wedge$}{\string^}(x\+\_\+i) / sum(2\texorpdfstring{$^\wedge$}{\string^}x\+\_\+j)

The relative output will be different here. But mathematically, the gradient will be the same with a log(2) scaling factor. 

Definition at line \mbox{\hyperlink{arm__softmax__q15_8c_source_l00061}{61}} of file \mbox{\hyperlink{arm__softmax__q15_8c_source}{arm\+\_\+softmax\+\_\+q15.\+c}}.

\Hypertarget{group___softmax_ga89aff212a97a3cf32d9d7ddf11a8f43e}\index{Softmax Functions@{Softmax Functions}!arm\_softmax\_q7@{arm\_softmax\_q7}}
\index{arm\_softmax\_q7@{arm\_softmax\_q7}!Softmax Functions@{Softmax Functions}}
\doxysubsubsubsection{\texorpdfstring{arm\_softmax\_q7()}{arm\_softmax\_q7()}}
{\footnotesize\ttfamily \label{group___softmax_ga89aff212a97a3cf32d9d7ddf11a8f43e} 
void arm\+\_\+softmax\+\_\+q7 (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{arm__math__types_8h_ae541b6f232c305361e9b416fc9eed263}{q7\+\_\+t}} \texorpdfstring{$\ast$}{*}}]{vec\+\_\+in}{, }\item[{const uint16\+\_\+t}]{dim\+\_\+vec}{, }\item[{\mbox{\hyperlink{arm__math__types_8h_ae541b6f232c305361e9b416fc9eed263}{q7\+\_\+t}} \texorpdfstring{$\ast$}{*}}]{p\+\_\+out}{}\end{DoxyParamCaption})}



Q7 softmax function. 


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{in}}  & {\em vec\+\_\+in} & pointer to input vector \\
\hline
\mbox{\texttt{in}}  & {\em dim\+\_\+vec} & input vector dimention \\
\hline
\mbox{\texttt{out}}  & {\em p\+\_\+out} & pointer to output vector\\
\hline
\end{DoxyParams}
Here, instead of typical natural logarithm e based softmax, we use 2-\/based softmax here, i.\+e.,\+:

y\+\_\+i = 2\texorpdfstring{$^\wedge$}{\string^}(x\+\_\+i) / sum(2\texorpdfstring{$^\wedge$}{\string^}x\+\_\+j)

The relative output will be different here. But mathematically, the gradient will be the same with a log(2) scaling factor. 

Definition at line \mbox{\hyperlink{arm__softmax__q7_8c_source_l00061}{61}} of file \mbox{\hyperlink{arm__softmax__q7_8c_source}{arm\+\_\+softmax\+\_\+q7.\+c}}.

Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=346pt]{group___softmax_ga89aff212a97a3cf32d9d7ddf11a8f43e_icgraph}
\end{center}
\end{figure}
\Hypertarget{group___softmax_ga3bc3ad13727a8a9d2cf7d0fba1209879}\index{Softmax Functions@{Softmax Functions}!arm\_softmax\_s16@{arm\_softmax\_s16}}
\index{arm\_softmax\_s16@{arm\_softmax\_s16}!Softmax Functions@{Softmax Functions}}
\doxysubsubsubsection{\texorpdfstring{arm\_softmax\_s16()}{arm\_softmax\_s16()}}
{\footnotesize\ttfamily \label{group___softmax_ga3bc3ad13727a8a9d2cf7d0fba1209879} 
\mbox{\hyperlink{arm__math__types_8h_a5e459c6409dfcd2927bb8a57491d7cf6}{arm\+\_\+status}} arm\+\_\+softmax\+\_\+s16 (\begin{DoxyParamCaption}\item[{const int16\+\_\+t \texorpdfstring{$\ast$}{*}}]{input}{, }\item[{const int32\+\_\+t}]{num\+\_\+rows}{, }\item[{const int32\+\_\+t}]{row\+\_\+size}{, }\item[{const int32\+\_\+t}]{mult}{, }\item[{const int32\+\_\+t}]{shift}{, }\item[{const \mbox{\hyperlink{structcmsis__nn__softmax__lut__s16}{cmsis\+\_\+nn\+\_\+softmax\+\_\+lut\+\_\+s16}} \texorpdfstring{$\ast$}{*}}]{softmax\+\_\+params}{, }\item[{int16\+\_\+t \texorpdfstring{$\ast$}{*}}]{output}{}\end{DoxyParamCaption})}



S16 softmax function. 


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{in}}  & {\em input} & Pointer to the input tensor \\
\hline
\mbox{\texttt{in}}  & {\em num\+\_\+rows} & Number of rows in the input tensor \\
\hline
\mbox{\texttt{in}}  & {\em row\+\_\+size} & Number of elements in each input row \\
\hline
\mbox{\texttt{in}}  & {\em mult} & Input quantization multiplier \\
\hline
\mbox{\texttt{in}}  & {\em shift} & Input quantization shift within the range \mbox{[}0, 31\mbox{]} \\
\hline
\mbox{\texttt{in}}  & {\em softmax\+\_\+params} & Softmax s16 layer parameters with two pointers to LUTs speficied below. For indexing the high 9 bits are used and 7 remaining for interpolation. That means 512 entries for the 9-\/bit indexing and 1 extra for interpolation, i.\+e. 513 values for each LUT.
\begin{DoxyItemize}
\item Lookup table for exp(x), where x uniform distributed between \mbox{[}-\/10.\+0 , 0.\+0\mbox{]}
\item Lookup table for 1 / (1 + x), where x uniform distributed between \mbox{[}0.\+0 , 1.\+0\mbox{]} 
\end{DoxyItemize}\\
\hline
\mbox{\texttt{out}}  & {\em output} & Pointer to the output tensor \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
The function returns {\ttfamily ARM\+\_\+\+MATH\+\_\+\+ARGUMENT\+\_\+\+ERROR} if LUTs are NULL {\ttfamily ARM\+\_\+\+MATH\+\_\+\+SUCCESS} -\/ Successful operation
\end{DoxyReturn}
\begin{DoxyNote}{Note}
Supported framework\+: Tensor\+Flow Lite micro (bit-\/accurate) 
\end{DoxyNote}


Definition at line \mbox{\hyperlink{arm__softmax__s16_8c_source_l00039}{39}} of file \mbox{\hyperlink{arm__softmax__s16_8c_source}{arm\+\_\+softmax\+\_\+s16.\+c}}.

Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{group___softmax_ga3bc3ad13727a8a9d2cf7d0fba1209879_cgraph}
\end{center}
\end{figure}
\Hypertarget{group___softmax_gaf309cdd53978a85a39c9bfdc476aea17}\index{Softmax Functions@{Softmax Functions}!arm\_softmax\_s8@{arm\_softmax\_s8}}
\index{arm\_softmax\_s8@{arm\_softmax\_s8}!Softmax Functions@{Softmax Functions}}
\doxysubsubsubsection{\texorpdfstring{arm\_softmax\_s8()}{arm\_softmax\_s8()}}
{\footnotesize\ttfamily \label{group___softmax_gaf309cdd53978a85a39c9bfdc476aea17} 
void arm\+\_\+softmax\+\_\+s8 (\begin{DoxyParamCaption}\item[{const int8\+\_\+t \texorpdfstring{$\ast$}{*}}]{input}{, }\item[{const int32\+\_\+t}]{num\+\_\+rows}{, }\item[{const int32\+\_\+t}]{row\+\_\+size}{, }\item[{const int32\+\_\+t}]{mult}{, }\item[{const int32\+\_\+t}]{shift}{, }\item[{const int32\+\_\+t}]{diff\+\_\+min}{, }\item[{int8\+\_\+t \texorpdfstring{$\ast$}{*}}]{output}{}\end{DoxyParamCaption})}



S8 softmax function. 


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{in}}  & {\em input} & Pointer to the input tensor \\
\hline
\mbox{\texttt{in}}  & {\em num\+\_\+rows} & Number of rows in the input tensor \\
\hline
\mbox{\texttt{in}}  & {\em row\+\_\+size} & Number of elements in each input row \\
\hline
\mbox{\texttt{in}}  & {\em mult} & Input quantization multiplier \\
\hline
\mbox{\texttt{in}}  & {\em shift} & Input quantization shift within the range \mbox{[}0, 31\mbox{]} \\
\hline
\mbox{\texttt{in}}  & {\em diff\+\_\+min} & Minimum difference with max in row. Used to check if the quantized exponential operation can be performed \\
\hline
\mbox{\texttt{out}}  & {\em output} & Pointer to the output tensor\\
\hline
\end{DoxyParams}
\begin{DoxyNote}{Note}
Supported framework\+: Tensor\+Flow Lite micro (bit-\/accurate) 
\end{DoxyNote}


Definition at line \mbox{\hyperlink{arm__softmax__s8_8c_source_l00086}{86}} of file \mbox{\hyperlink{arm__softmax__s8_8c_source}{arm\+\_\+softmax\+\_\+s8.\+c}}.

Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{group___softmax_gaf309cdd53978a85a39c9bfdc476aea17_cgraph}
\end{center}
\end{figure}
\Hypertarget{group___softmax_ga4c00979132b735e75525296bb5fa830f}\index{Softmax Functions@{Softmax Functions}!arm\_softmax\_s8\_s16@{arm\_softmax\_s8\_s16}}
\index{arm\_softmax\_s8\_s16@{arm\_softmax\_s8\_s16}!Softmax Functions@{Softmax Functions}}
\doxysubsubsubsection{\texorpdfstring{arm\_softmax\_s8\_s16()}{arm\_softmax\_s8\_s16()}}
{\footnotesize\ttfamily \label{group___softmax_ga4c00979132b735e75525296bb5fa830f} 
void arm\+\_\+softmax\+\_\+s8\+\_\+s16 (\begin{DoxyParamCaption}\item[{const int8\+\_\+t \texorpdfstring{$\ast$}{*}}]{input}{, }\item[{const int32\+\_\+t}]{num\+\_\+rows}{, }\item[{const int32\+\_\+t}]{row\+\_\+size}{, }\item[{const int32\+\_\+t}]{mult}{, }\item[{const int32\+\_\+t}]{shift}{, }\item[{const int32\+\_\+t}]{diff\+\_\+min}{, }\item[{int16\+\_\+t \texorpdfstring{$\ast$}{*}}]{output}{}\end{DoxyParamCaption})}



S8 to s16 softmax function. 


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{in}}  & {\em input} & Pointer to the input tensor \\
\hline
\mbox{\texttt{in}}  & {\em num\+\_\+rows} & Number of rows in the input tensor \\
\hline
\mbox{\texttt{in}}  & {\em row\+\_\+size} & Number of elements in each input row \\
\hline
\mbox{\texttt{in}}  & {\em mult} & Input quantization multiplier \\
\hline
\mbox{\texttt{in}}  & {\em shift} & Input quantization shift within the range \mbox{[}0, 31\mbox{]} \\
\hline
\mbox{\texttt{in}}  & {\em diff\+\_\+min} & Minimum difference with max in row. Used to check if the quantized exponential operation can be performed \\
\hline
\mbox{\texttt{out}}  & {\em output} & Pointer to the output tensor\\
\hline
\end{DoxyParams}
\begin{DoxyNote}{Note}
Supported framework\+: Tensor\+Flow Lite micro (bit-\/accurate) 
\end{DoxyNote}


Definition at line \mbox{\hyperlink{arm__softmax__s8__s16_8c_source_l00043}{43}} of file \mbox{\hyperlink{arm__softmax__s8__s16_8c_source}{arm\+\_\+softmax\+\_\+s8\+\_\+s16.\+c}}.

Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{group___softmax_ga4c00979132b735e75525296bb5fa830f_cgraph}
\end{center}
\end{figure}
\Hypertarget{group___softmax_gaa1627ed96bd597a8046d00689f077dce}\index{Softmax Functions@{Softmax Functions}!arm\_softmax\_u8@{arm\_softmax\_u8}}
\index{arm\_softmax\_u8@{arm\_softmax\_u8}!Softmax Functions@{Softmax Functions}}
\doxysubsubsubsection{\texorpdfstring{arm\_softmax\_u8()}{arm\_softmax\_u8()}}
{\footnotesize\ttfamily \label{group___softmax_gaa1627ed96bd597a8046d00689f077dce} 
void arm\+\_\+softmax\+\_\+u8 (\begin{DoxyParamCaption}\item[{const uint8\+\_\+t \texorpdfstring{$\ast$}{*}}]{input}{, }\item[{const int32\+\_\+t}]{num\+\_\+rows}{, }\item[{const int32\+\_\+t}]{row\+\_\+size}{, }\item[{const int32\+\_\+t}]{mult}{, }\item[{const int32\+\_\+t}]{shift}{, }\item[{const int32\+\_\+t}]{diff\+\_\+min}{, }\item[{uint8\+\_\+t \texorpdfstring{$\ast$}{*}}]{output}{}\end{DoxyParamCaption})}



U8 softmax function. 


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{in}}  & {\em input} & Pointer to the input tensor \\
\hline
\mbox{\texttt{in}}  & {\em num\+\_\+rows} & Number of rows in the input tensor \\
\hline
\mbox{\texttt{in}}  & {\em row\+\_\+size} & Number of elements in each input row \\
\hline
\mbox{\texttt{in}}  & {\em mult} & Input quantization multiplier \\
\hline
\mbox{\texttt{in}}  & {\em shift} & Input quantization shift within the range \mbox{[}0, 31\mbox{]} \\
\hline
\mbox{\texttt{in}}  & {\em diff\+\_\+min} & Minimum difference with max in row. Used to check if the quantized exponential operation can be performed \\
\hline
\mbox{\texttt{out}}  & {\em output} & Pointer to the output tensor\\
\hline
\end{DoxyParams}
\begin{DoxyNote}{Note}
Supported framework\+: Tensor\+Flow Lite micro (bit-\/accurate) 
\end{DoxyNote}


Definition at line \mbox{\hyperlink{arm__softmax__u8_8c_source_l00044}{44}} of file \mbox{\hyperlink{arm__softmax__u8_8c_source}{arm\+\_\+softmax\+\_\+u8.\+c}}.

\Hypertarget{group___softmax_ga894cfd80c260b946702755b5754e520f}\index{Softmax Functions@{Softmax Functions}!arm\_softmax\_with\_batch\_q7@{arm\_softmax\_with\_batch\_q7}}
\index{arm\_softmax\_with\_batch\_q7@{arm\_softmax\_with\_batch\_q7}!Softmax Functions@{Softmax Functions}}
\doxysubsubsubsection{\texorpdfstring{arm\_softmax\_with\_batch\_q7()}{arm\_softmax\_with\_batch\_q7()}}
{\footnotesize\ttfamily \label{group___softmax_ga894cfd80c260b946702755b5754e520f} 
void arm\+\_\+softmax\+\_\+with\+\_\+batch\+\_\+q7 (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{arm__math__types_8h_ae541b6f232c305361e9b416fc9eed263}{q7\+\_\+t}} \texorpdfstring{$\ast$}{*}}]{vec\+\_\+in}{, }\item[{const uint16\+\_\+t}]{nb\+\_\+batches}{, }\item[{const uint16\+\_\+t}]{dim\+\_\+vec}{, }\item[{\mbox{\hyperlink{arm__math__types_8h_ae541b6f232c305361e9b416fc9eed263}{q7\+\_\+t}} \texorpdfstring{$\ast$}{*}}]{p\+\_\+out}{}\end{DoxyParamCaption})}



Q7 softmax function with batch parameter. 


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{in}}  & {\em vec\+\_\+in} & pointer to input vector \\
\hline
\mbox{\texttt{in}}  & {\em nb\+\_\+batches} & number of batches \\
\hline
\mbox{\texttt{in}}  & {\em dim\+\_\+vec} & input vector dimention \\
\hline
\mbox{\texttt{out}}  & {\em p\+\_\+out} & pointer to output vector\\
\hline
\end{DoxyParams}
Here, instead of typical natural logarithm e based softmax, we use 2-\/based softmax here, i.\+e.,\+:

y\+\_\+i = 2\texorpdfstring{$^\wedge$}{\string^}(x\+\_\+i) / sum(2\texorpdfstring{$^\wedge$}{\string^}x\+\_\+j)

The relative output will be different here. But mathematically, the gradient will be the same with a log(2) scaling factor. 

Definition at line \mbox{\hyperlink{arm__softmax__with__batch__q7_8c_source_l00062}{62}} of file \mbox{\hyperlink{arm__softmax__with__batch__q7_8c_source}{arm\+\_\+softmax\+\_\+with\+\_\+batch\+\_\+q7.\+c}}.

Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=346pt]{group___softmax_ga894cfd80c260b946702755b5754e520f_cgraph}
\end{center}
\end{figure}
